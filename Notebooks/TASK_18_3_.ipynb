{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=blue>**P16.**</font> ```for word in line.split()``` â€“ looping over strings and splitting by any delimiter"
      ],
      "metadata": {
        "id": "WD5wnvQkmh6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TASK P16.1** Print each word in the ROSALIND Problem #5 Sample Dataset on a separate line.\n"
      ],
      "metadata": {
        "id": "kApNvgOLn8lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"rosalind_ini6_1157_1_dataset.txt\",\"r\") as data:\n",
        "\n",
        "  line=data.read()\n",
        "\n",
        "for word in line.split():\n",
        "    print (word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBjyhwclpKoM",
        "outputId": "9dbabdda-eeee-4dda-e6a6-2a4352012767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When\n",
            "I\n",
            "find\n",
            "myself\n",
            "in\n",
            "times\n",
            "of\n",
            "trouble\n",
            "Mother\n",
            "Mary\n",
            "comes\n",
            "to\n",
            "me\n",
            "Speaking\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n",
            "And\n",
            "in\n",
            "my\n",
            "hour\n",
            "of\n",
            "darkness\n",
            "she\n",
            "is\n",
            "standing\n",
            "right\n",
            "in\n",
            "front\n",
            "of\n",
            "me\n",
            "Speaking\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n",
            "Let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "Whisper\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n",
            "And\n",
            "when\n",
            "the\n",
            "broken\n",
            "hearted\n",
            "people\n",
            "living\n",
            "in\n",
            "the\n",
            "world\n",
            "agree\n",
            "There\n",
            "will\n",
            "be\n",
            "an\n",
            "answer\n",
            "let\n",
            "it\n",
            "be\n",
            "For\n",
            "though\n",
            "they\n",
            "may\n",
            "be\n",
            "parted\n",
            "there\n",
            "is\n",
            "still\n",
            "a\n",
            "chance\n",
            "that\n",
            "they\n",
            "will\n",
            "see\n",
            "There\n",
            "will\n",
            "be\n",
            "an\n",
            "answer\n",
            "let\n",
            "it\n",
            "be\n",
            "Let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "There\n",
            "will\n",
            "be\n",
            "an\n",
            "answer\n",
            "let\n",
            "it\n",
            "be\n",
            "Let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "Whisper\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n",
            "Let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "Whisper\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n",
            "And\n",
            "when\n",
            "the\n",
            "night\n",
            "is\n",
            "cloudy\n",
            "there\n",
            "is\n",
            "still\n",
            "a\n",
            "light\n",
            "that\n",
            "shines\n",
            "on\n",
            "me\n",
            "Shine\n",
            "until\n",
            "tomorrow\n",
            "let\n",
            "it\n",
            "be\n",
            "I\n",
            "wake\n",
            "up\n",
            "to\n",
            "the\n",
            "sound\n",
            "of\n",
            "music\n",
            "Mother\n",
            "Mary\n",
            "comes\n",
            "to\n",
            "me\n",
            "Speaking\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n",
            "Let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "yeah\n",
            "let\n",
            "it\n",
            "be\n",
            "There\n",
            "will\n",
            "be\n",
            "an\n",
            "answer\n",
            "let\n",
            "it\n",
            "be\n",
            "Let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "let\n",
            "it\n",
            "be\n",
            "yeah\n",
            "let\n",
            "it\n",
            "be\n",
            "Whisper\n",
            "words\n",
            "of\n",
            "wisdom\n",
            "let\n",
            "it\n",
            "be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=blue>**P17.**</font> Python Dictionaries { }"
      ],
      "metadata": {
        "id": "kq9QbEttnA4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TASK 17.1** Create and print your first dictionary"
      ],
      "metadata": {
        "id": "lVudFQkZqJgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = {\n",
        "    \"H.neandertalensis\":\"ACGTCGCTCTGCTA\",\n",
        "    \"H.sapiens\":\"ACGTCACTCTGCTA\"\n",
        "    }\n",
        "\n",
        "print (sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzKFWDlgq6zo",
        "outputId": "5e417ee4-4a69-407c-ffd8-2229c8efd119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'H.neandertalensis': 'ACGTCGCTCTGCTA', 'H.sapiens': 'ACGTCACTCTGCTA'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=blue>**P18.**</font> Manipulating and printing dictionaries"
      ],
      "metadata": {
        "id": "OvqoT6UwnK0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TASK 18.1** Modify line 8 to create a fasta file of the hominid sequences"
      ],
      "metadata": {
        "id": "5Be2tcQRrjso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[\"P.troglodytes\"]=\"ACGTCACTCTCCTA\"\n",
        "\n",
        "sequences.update({\"G.gorilla\":\"ACGTCCTCCTA\", \"H.erectus\":\"ACGTCACTCTGCTA\"})\n",
        "\n",
        "print (sequences[\"H.sapiens\"])\n",
        "\n",
        "for key,value in sequences.items():\n",
        "     print (key,value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-2XDof4rtP8",
        "outputId": "0c8f61b3-e029-47ba-a392-657f4a0cdfad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACGTCACTCTGCTA\n",
            "H.neandertalensis ACGTCGCTCTGCTA\n",
            "H.sapiens ACGTCACTCTGCTA\n",
            "P.troglodytes ACGTCACTCTCCTA\n",
            "G.gorilla ACGTCCTCCTA\n",
            "H.erectus ACGTCACTCTGCTA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TASK P18.2** <font color= orange>**Complete Rosalind Problem #5  Dictionaries**</font>"
      ],
      "metadata": {
        "id": "Y98OZYUNvmWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rosalind Problem #5\n",
        "with open(\"rosalind_ini6_1157_1_dataset.txt\", \"r\") as f:\n",
        "    text = f.read().strip()\n",
        "\n",
        "# Split into words\n",
        "words = text.split()\n",
        "\n",
        "# Count occurrences using a dictionary\n",
        "word_count = {}\n",
        "for word in words:\n",
        "    word_count[word] = word_count.get(word, 0) + 1\n",
        "\n",
        "# Print results\n",
        "for word, count in word_count.items():\n",
        "    print(word, count)\n"
      ],
      "metadata": {
        "id": "lD3KoTY9wWa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17af8db9-9be8-4b33-95f6-a5fe6065d10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When 1\n",
            "I 2\n",
            "find 1\n",
            "myself 1\n",
            "in 4\n",
            "times 1\n",
            "of 11\n",
            "trouble 1\n",
            "Mother 2\n",
            "Mary 2\n",
            "comes 2\n",
            "to 3\n",
            "me 4\n",
            "Speaking 3\n",
            "words 7\n",
            "wisdom 7\n",
            "let 30\n",
            "it 36\n",
            "be 41\n",
            "And 3\n",
            "my 1\n",
            "hour 1\n",
            "darkness 1\n",
            "she 1\n",
            "is 4\n",
            "standing 1\n",
            "right 1\n",
            "front 1\n",
            "Let 6\n",
            "Whisper 4\n",
            "when 2\n",
            "the 4\n",
            "broken 1\n",
            "hearted 1\n",
            "people 1\n",
            "living 1\n",
            "world 1\n",
            "agree 1\n",
            "There 4\n",
            "will 5\n",
            "an 4\n",
            "answer 4\n",
            "For 1\n",
            "though 1\n",
            "they 2\n",
            "may 1\n",
            "parted 1\n",
            "there 2\n",
            "still 2\n",
            "a 2\n",
            "chance 1\n",
            "that 2\n",
            "see 1\n",
            "night 1\n",
            "cloudy 1\n",
            "light 1\n",
            "shines 1\n",
            "on 1\n",
            "Shine 1\n",
            "until 1\n",
            "tomorrow 1\n",
            "wake 1\n",
            "up 1\n",
            "sound 1\n",
            "music 1\n",
            "yeah 2\n"
          ]
        }
      ]
    }
  ]
}